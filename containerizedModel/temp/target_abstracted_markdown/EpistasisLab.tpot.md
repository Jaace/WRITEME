Master status: @abstr_hyperlink @abstr_hyperlink @abstr_hyperlink 

Development status: @abstr_hyperlink @abstr_hyperlink @abstr_hyperlink 

Package information: @abstr_hyperlink @abstr_hyperlink @abstr_hyperlink @abstr_hyperlink 

@abstr_image 

Consider TPOT your **Data Science Assistant**. TPOT is a Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming.

@abstr_image 

TPOT will automate the most tedious part of machine learning by intelligently exploring thousands of possible pipelines to find the best one for your data.

@abstr_image 

**An example Machine Learning pipeline**

Once TPOT is finished searching (or you get tired of waiting), it provides you with the Python code for the best pipeline it found so you can tinker with the pipeline from there.

@abstr_image 

TPOT is built on top of scikit-learn, so all of the code it generates should look familiar... if you're familiar with scikit-learn, anyway.

**TPOT is still under active development** and we encourage you to check back on this repository regularly for updates.

For further information about TPOT, please see the @abstr_hyperlink .

## License

Please see the @abstr_hyperlink for the licensing and usage information for TPOT.

Generally, we have licensed TPOT to make it as widely usable as possible.

## Installation

We maintain the @abstr_hyperlink in the documentation. TPOT requires a working installation of Python.

## Usage

TPOT can be used @abstr_hyperlink or @abstr_hyperlink .

Click on the corresponding links to find more information on TPOT usage in the documentation.

## Examples

### Classification

Below is a minimal working example with the practice MNIST data set.

@abstr_code_section 

Running this code should discover a pipeline that achieves about @abstr_number % testing accuracy, and the corresponding Python code should be exported to the `tpot_mnist_pipeline.py` file and look similar to the following:

@abstr_code_section 

### Regression

Similarly, TPOT can optimize pipelines for regression problems. Below is a minimal working example with the practice Boston housing prices data set.

@abstr_code_section 

which should result in a pipeline that achieves about @abstr_number . @abstr_number mean squared error (MSE), and the Python code in `tpot_boston_pipeline.py` should look similar to:

@abstr_code_section 

Check the documentation for @abstr_hyperlink .

## Contributing to TPOT

We welcome you to @abstr_hyperlink for bugs or enhancements to work on. If you have an idea for an extension to TPOT, please @abstr_hyperlink so we can discuss it.

Before submitting any contributions, please review our @abstr_hyperlink .

## Having problems or have questions about TPOT?

Please @abstr_hyperlink to see if your issue has already been attended to. If it hasn't, @abstr_hyperlink on this repository so we can review your issue.

## Citing TPOT

If you use TPOT in a scientific publication, please consider citing at least one of the following papers:

Randal S. Olson, Ryan J. Urbanowicz, Peter C. Andrews, Nicole A. Lavender, La Creis Kidd, and Jason H. Moore ( @abstr_number ). @abstr_hyperlink . _Applications of Evolutionary Computation_ , pages @abstr_number - @abstr_number .

BibTeX entry:

@abstr_code_section 

Randal S. Olson, Nathan Bartley, Ryan J. Urbanowicz, and Jason H. Moore ( @abstr_number ). @abstr_hyperlink . *Proceedings of GECCO @abstr_number *, pages @abstr_number - @abstr_number .

BibTeX entry:

@abstr_code_section 

Alternatively, you can cite the repository directly with the following DOI:

@abstr_hyperlink 

## Support for TPOT

TPOT was developed in the @abstr_hyperlink at the @abstr_hyperlink with funding from the @abstr_hyperlink under grant R @abstr_number AI @abstr_number . We are incredibly grateful for the support of the NIH and the University of Pennsylvania during the development of this project.

The TPOT logo was designed by Todd Newmuis, who generously donated his time to the project.
