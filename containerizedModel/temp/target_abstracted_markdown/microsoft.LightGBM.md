# LightGBM, Light Gradient Boosting Machine

@abstr_hyperlink @abstr_hyperlink @abstr_hyperlink @abstr_hyperlink @abstr_hyperlink @abstr_hyperlink @abstr_hyperlink @abstr_hyperlink @abstr_hyperlink 

LightGBM is a gradient boosting framework that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages:

  * Faster training speed and higher efficiency.
  * Lower memory usage.
  * Better accuracy.
  * Support of parallel and GPU learning.
  * Capable of handling large-scale data.



For further details, please refer to @abstr_hyperlink .

Benefitting from these advantages, LightGBM is being widely-used in many @abstr_hyperlink of machine learning competitions.

@abstr_hyperlink on public datasets show that LightGBM can outperform existing boosting frameworks on both efficiency and accuracy, with significantly lower memory consumption. What's more, @abstr_hyperlink show that LightGBM can achieve a linear speed-up by using multiple machines for training in specific settings.

## Get Started and Documentation

Our primary documentation is at https://lightgbm.readthedocs.io/ and is generated from this repository. If you are new to LightGBM, follow @abstr_hyperlink on that site.

Next you may want to read:

  * @abstr_hyperlink showing command line usage of common tasks.
  * @abstr_hyperlink and algorithms supported by LightGBM.
  * @abstr_hyperlink is an exhaustive list of customization you can make.
  * @abstr_hyperlink and @abstr_hyperlink can speed up computation.
  * @abstr_hyperlink is a detailed guide for hyperparameters.



Documentation for contributors:

  * @abstr_hyperlink .
  * Check out the @abstr_hyperlink .



## News

@abstr_number / @abstr_number / @abstr_number : Optimal split for categorical features.

@abstr_number / @abstr_number / @abstr_number : @abstr_hyperlink is available.

@abstr_number / @abstr_number / @abstr_number : Python-package is on @abstr_hyperlink now.

@abstr_number / @abstr_number / @abstr_number : @abstr_hyperlink is available.

@abstr_number / @abstr_number / @abstr_number : LightGBM v @abstr_number stable release.

@abstr_number / @abstr_number / @abstr_number : LightGBM supports GPU-accelerated tree learning now. Please read our GPU Tutorial and Performance Comparison.

@abstr_number / @abstr_number / @abstr_number : Update to LightGBM v @abstr_number .

@abstr_number / @abstr_number / @abstr_number : LightGBM v @abstr_number stable release.

@abstr_number / @abstr_number / @abstr_number : Release @abstr_hyperlink beta version, welcome to have a try and provide feedback.

@abstr_number / @abstr_number / @abstr_number : **Categorical Features as input directly** (without one-hot coding). 

@abstr_number / @abstr_number / @abstr_number : Release @abstr_hyperlink beta version, welcome to have a try and provide feedback.

More detailed update logs : @abstr_hyperlink .

## External (Unofficial) Repositories

Julia-package: https://github.com/Allardvm/LightGBM.jl

JPMML (Java PMML converter): https://github.com/jpmml/jpmml-lightgbm

Treelite (model compiler for efficient deployment): https://github.com/dmlc/treelite

ONNXMLTools (ONNX converter): https://github.com/onnx/onnxmltools

SHAP (model output explainer): https://github.com/slundberg/shap

MMLSpark (Spark-package): https://github.com/Azure/mmlspark

ML.NET (.NET/C#-package): https://github.com/dotnet/machinelearning

LightGBM.NET (.NET/C#-package): https://github.com/rca @abstr_number /LightGBM.Net

Dask-LightGBM (distributed and parallel Python-package): https://github.com/dask/dask-lightgbm

## Support

  * Ask a question @abstr_hyperlink , we monitor this for new questions.
  * Discuss on the @abstr_hyperlink .
  * Discuss on the @abstr_hyperlink . 
    * Use @abstr_hyperlink to join the team.
  * Open **bug reports** and **feature requests** (not questions) on @abstr_hyperlink .



## How to Contribute

LightGBM has been developed and used by many active community members. Your help is very valuable to make it better for everyone.

  * Contribute to the @abstr_hyperlink to make it more reliable.
  * Contribute to the @abstr_hyperlink to make it clearer for everyone.
  * Contribute to the @abstr_hyperlink to share your experience with other users.
  * Look for @abstr_hyperlink and submit pull requests to address them.
  * Add your stories and experience to @abstr_hyperlink . If LightGBM helped you in a machine learning competition or some research application, we want to hear about it!
  * @abstr_hyperlink to report problems or recommend new features.



## Microsoft Open Source Code of Conduct

This project has adopted the @abstr_hyperlink . For more information see the @abstr_hyperlink or contact @abstr_hyperlink with any additional questions or comments.

## Reference Papers

Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, Tie-Yan Liu. " @abstr_hyperlink ". Advances in Neural Information Processing Systems @abstr_number (NIPS @abstr_number ), pp. @abstr_number - @abstr_number .

Qi Meng, Guolin Ke, Taifeng Wang, Wei Chen, Qiwei Ye, Zhi-Ming Ma, Tie-Yan Liu. " @abstr_hyperlink ". Advances in Neural Information Processing Systems @abstr_number (NIPS @abstr_number ), pp. @abstr_number - @abstr_number .

Huan Zhang, Si Si and Cho-Jui Hsieh. " @abstr_hyperlink ". SysML Conference, @abstr_number .

**Note** : If you use LightGBM in your GitHub projects, please add `lightgbm` in the `requirements.txt`.

## License

This project is licensed under the terms of the MIT license. See @abstr_hyperlink for additional details.
